


#测试环境：------------------------
#local_daily_dir=C:\\Users\\SAM\\Desktop\\test\\anda_data
#
#Calendar.HOUR_OF_DAY=22
#Calendar.MINUTE=00

#util setup
#windows_filename_seperator=\\

#日志写入SQL SERVER;




#部署环境：------------------------
#new_store设置： 从服务器上获取输入文件，运行在185。 我的程序是从193本地获取文件,运行在193。
new_input_basicPath=\\\\Drfssh001\\ftp\\RetailData\\Anda\\
#new_output_basicPath=\\\\DRFSSH001\\DataReal_Data\\DAILY
new_output_basicPath_store=\\\\DRFSSH001\\DataReal_Data\\DAILY\\NEWSTORE\\
new_output_basicPath_product=\\\\DRFSSH001\\DataReal_Data\\DAILY\\NEWITEM\\
new_store_default_name=R10003_ANDA_new_store.csv
new_product_default_name=R10003_ANDA_new_product.csv

time_to_start=15
#MAIL TO ME
mail_sender_address=sam.gao@datarealglobal.com
mail_password=Gao123456
mail_receiver_address=sam.gao@datarealglobal.com

#FTP-ANDA
FtpIP=192.168.0.193
ftpPort=21
username=anda_user
password=andaanddatareal
ftp_default_dir=/

#定时每天执行
Calendar.HOUR_OF_DAY=11
Calendar.MINUTE=00

#185本地中转目录
local_daily_dir=/home/etl/samgao/anda_daily
#Hadoop cluster
fs.default.name=hdfs://192.168.0.151:9000
hdfs_des_dir=/usr/samgao/input/anda/

#util setup
linux_filename_seperator=/


#MYJ
#FtpIP=58.255.36.210
#ftpPort=2121
#FtpDefaultDirectory=/
#username=datacenter
#password=123abc++
