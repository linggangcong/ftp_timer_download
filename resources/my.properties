


#测试环境：------------------------
#local_daily_dir=C:\\Users\\SAM\\Desktop\\test\\anda_data
#
#Calendar.HOUR_OF_DAY=22
#Calendar.MINUTE=00

#util setup
#windows_filename_seperator=\\

#日志写入SQL SERVER;
anda.etl.log.to.sql_server=true
#sqlserver 的一些配置
sql.sqlServer.connect.url=jdbc:sqlserver://192.168.0.193:1433;DatabaseName=IMDb
sql.sqlServer.new_banner_goods_table_name=new_banner_goods
sql.sqlServer.new_banner_store_table_name=new_banner_store
sql.sqlServer.user=sa
sql.sqlServer.password=dr123456780
#sqlserver 连接的url
sqlserver.connect.url=jdbc:sqlserver://192.168.0.193:1433;DatabaseName=IMDb;username=sa;password=dr12345678



#部署环境：------------------------
#new_store设置： 从服务器上获取输入文件，运行在185。 我的程序是从193本地获取文件,运行在193。
new_input_basicPath=\\\\Drfssh001\\ftp\\RetailData\\Anda\\
#new_output_basicPath=\\\\DRFSSH001\\DataReal_Data\\DAILY
new_output_basicPath_store=\\\\DRFSSH001\\DataReal_Data\\DAILY\\NEWSTORE\\
new_output_basicPath_product=\\\\DRFSSH001\\DataReal_Data\\DAILY\\NEWITEM\\
new_store_default_name=R10003_ANDA_new_store.csv
new_product_default_name=R10003_ANDA_new_product.csv

time_to_start=15
#MAIL TO ME
mail_sender_address=sam.gao@datarealglobal.com
mail_password=Gao123456
mail_receiver_address=sam.gao@datarealglobal.com

#FTP-ANDA
FtpIP=192.168.0.193
ftpPort=21
username=anda_user
password=andaanddatareal
ftp_default_dir=/

#定时每天执行
Calendar.HOUR_OF_DAY=11
Calendar.MINUTE=00

#185本地中转目录
local_daily_dir=/home/etl/samgao/anda_daily
#Hadoop cluster
fs.default.name=hdfs://192.168.0.151:9000
hdfs_des_dir=/usr/samgao/input/anda/

#util setup
linux_filename_seperator=/


#MYJ
#FtpIP=58.255.36.210
#ftpPort=2121
#FtpDefaultDirectory=/
#username=datacenter
#password=123abc++
